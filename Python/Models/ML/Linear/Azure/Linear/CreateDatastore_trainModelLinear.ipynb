{"cells":[{"cell_type":"markdown","source":["# Loan Approval from Historical Data on Azure: Create Datastore & Train Linear Model"],"metadata":{"id":"Qxfr585nRyx4"}},{"cell_type":"markdown","source":["## Create an Azure Files Datastore\n","Connect to the Azure Machine Learning workspace with `MLClient`."],"metadata":{"nteract":{"transient":{"deleting":false}},"id":"8sl7d2XxZ27E"}},{"cell_type":"code","source":["from azure.ai.ml import MLClient\n","from azure.identity import DefaultAzureCredential\n","\n","# Authenticate\n","credential = DefaultAzureCredential()\n","\n","# Get a handle to the workspace\n","ml_client = MLClient(\n","    credential=credential,\n","    subscription_id='a134465f-eb15-4297-b902-3c97d4c81838',\n","    resource_group_name='aschultzdata',\n","    workspace_name='ds-ml-env',\n",")"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1691262495542},"id":"InQvmfQeGllH"}},{"cell_type":"markdown","source":["Create the datastore specifying the name of the datastore, the description, the account, the name of the container, the protocol and the account key."],"metadata":{"id":"pZg34BcT_Q3h"}},{"cell_type":"code","source":["from azure.ai.ml.entities import AzureBlobDatastore\n","from azure.ai.ml.entities import AccountKeyConfiguration\n","from azure.ai.ml import MLClient\n","\n","\n","store = AzureBlobDatastore(\n","    name='loanstatus_datastore',\n","    description='Datastore for Loan Status',\n","    account_name='dsmlenv8898281366',\n","    container_name='loanstatus',\n","    protocol='https',\n","    credentials=AccountKeyConfiguration(\n","        account_key='XXXxxxXXXxXXXXxxXXXXXxXXXXXxXxxXxXXXxXXXxXXxxxXXxxXXXxXxXXXxxXxxXXXXxxxxxXXxxxxxxXXXxXXX'\n","    ),\n",")\n","\n","ml_client.create_or_update(store)"],"outputs":[{"output_type":"execute_result","execution_count":50,"data":{"text/plain":"AzureBlobDatastore({'type': <DatastoreType.AZURE_BLOB: 'AzureBlob'>, 'name': 'loanstatus_datastore', 'description': 'Datastore for Loan Status', 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': '/subscriptions/a134465f-eb15-4297-b902-3c97d4c81838/resourceGroups/aschultzdata/providers/Microsoft.MachineLearningServices/workspaces/ds-ml-env/datastores/loanstatus_datastore', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/cpu-standardds12v2/code/Users/aschultz.data/UsedCarsCarGurus/Models/DL/MLP', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f5450284f70>, 'credentials': {'type': 'account_key'}, 'container_name': 'loanstatus', 'account_name': 'dsmlenv8898281366', 'endpoint': 'core.windows.net', 'protocol': 'https'})"},"metadata":{}}],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1691268744044},"id":"LyfV64Q6Z27F","outputId":"76049ab0-665d-4878-ae03-09f1fde8a6b0"}},{"cell_type":"markdown","source":["Then upload the train/test sets to the `loanstatus` container."],"metadata":{"nteract":{"transient":{"deleting":false}},"id":"7EygsnQRZ27H"}},{"cell_type":"markdown","source":["# Train a model\n","First, create a compute instance to run a notebook in Azure Machine Learning studio. Then connect to the workspace and create the compute resource (CPU or GPU), if it has not all ready been created.\n","\n","\n"],"metadata":{"id":"0p0OqxR0Z26w"}},{"cell_type":"markdown","source":["## Create a compute cluster to run the job"],"metadata":{"id":"VzRhu2sHAOMt"}},{"cell_type":"code","source":["from azure.ai.ml.entities import AmlCompute\n","\n","# Define the name of the compute cluster\n","cpu_compute_target = 'cpu-cluster-E8s-v3'\n","\n","try:\n","    # Examine if the cluster already exists\n","    cpu_cluster = ml_client.compute.get(cpu_compute_target)\n","    print(\n","        f\"You already have a cluster named {cpu_compute_target}, we'll reuse it as is.\"\n","    )\n","\n","except Exception:\n","    print('Creating a new cpu compute target...')\n","\n","    # Create the Azure Machine Learning compute object with specified components\n","    cpu_cluster = AmlCompute(\n","        name=cpu_compute_target,\n","        # On-demand VM service\n","        type='amlcompute',\n","        # VM Family\n","        size='Standard_E8s_v3',\n","        # Minimum nodes in the cluster\n","        min_instances=0,\n","        # Nodes in the cluster\n","        max_instances=1,\n","        # Time (seconds) the node will run after the job finishes/terminates\n","        idle_time_before_scale_down=180,\n","        # Type of tier: Dedicated or LowPriority\n","        tier='Dedicated',\n","    )\n","    print(\n","        f\"AMLCompute with name {cpu_cluster.name} will be created, with compute size {cpu_cluster.size}\"\n","    )\n","    # Pass the object to MLClient's create_or_update method\n","    cpu_cluster = ml_client.compute.begin_create_or_update(cpu_cluster)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XBN7hyjrH88M","executionInfo":{"status":"ok","timestamp":1694047982827,"user_tz":240,"elapsed":6,"user":{"displayName":"Andrew Schultz","userId":"07163353164150645905"}},"outputId":"423ef4c7-751d-4c43-f4b2-ac061abb9ce1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Creating a new cpu compute target...\n","AMLCompute with name cpu-cluster-E8s-v3 will be created, with compute size Standard_E8s_v3\n"]}]},{"cell_type":"markdown","source":["## Create the job environment\n","The environment lists the components of the runtime and the libraries installed on the compute for training the model."],"metadata":{"id":"K5oMdA7qZ263"}},{"cell_type":"code","source":["import os\n","\n","dependencies_dir = './dependencies'\n","os.makedirs(dependencies_dir, exist_ok=True)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1691350975623},"id":"U4glUWAGE90O"}},{"cell_type":"markdown","source":["Now we can write the `conda` file into the `dependencies` directory."],"metadata":{"id":"L8TMRaMMZ265"}},{"cell_type":"code","source":["%%writefile {dependencies_dir}/conda.yaml\n","name: model-env\n","channels:\n","  - conda-forge\n","dependencies:\n","  - python=3.8.5\n","  - numpy=1.21.6\n","  - pip=23.1.2\n","  - scikit-learn==1.1.2\n","  - scipy\n","  - pandas>=1.1,<1.2\n","  - pip:\n","    - inference-schema[numpy-support]==1.3.0\n","    - mlflow\n","    - azureml-mlflow\n","    - psutil==5.9.0\n","    - tqdm\n","    - ipykernel\n","    - matplotlib\n","    - seaborn\n","    - eli5==0.13.0\n","    - shap==0.41.0\n","    - lime"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3JNgvRUIIbh_","executionInfo":{"status":"ok","timestamp":1694048055703,"user_tz":240,"elapsed":6,"user":{"displayName":"Andrew Schultz","userId":"07163353164150645905"}},"outputId":"c6142d13-1414-439d-892a-31c8fb064e88"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing ./dependencies/conda.yaml\n"]}]},{"cell_type":"markdown","source":["The created `conda.yaml` file allows for the environment to be created and registered in the workspace."],"metadata":{"id":"K1DU3gmfZ266"}},{"cell_type":"code","source":["from azure.ai.ml.entities import Environment\n","\n","custom_env_name = 'aml-loanstatus-cpu'\n","\n","custom_job_env = Environment(\n","    name=custom_env_name,\n","    description='Custom environment for Used Cars XGboost job',\n","    tags={'scikit-learn': '1.1.2'},\n","    conda_file=os.path.join(dependencies_dir, 'conda.yaml'),\n","    image='mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:latest',\n",")\n","custom_job_env = ml_client.environments.create_or_update(custom_job_env)\n","\n","print(\n","    f\"Environment with name {custom_job_env.name} is registered to workspace, the environment version is {custom_job_env.version}\"\n",")"],"outputs":[{"output_type":"stream","name":"stdout","text":"Environment with name aml-loanstatus-cpu is registered to workspace, the environment version is 2\n"}],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1691353979091},"id":"zKzKcSK8E90Q","outputId":"ff9c9fc9-b5bc-444d-dee1-f52eafb25d1a"}},{"cell_type":"markdown","source":["## Create training script\n","First, the source folder where the training script, `main.py`, will be stored needs to be created."],"metadata":{"id":"WeKknDz_Z268"}},{"cell_type":"code","source":["import os\n","\n","train_src_dir = './src'\n","os.makedirs(train_src_dir, exist_ok=True)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1691353981480},"id":"rmujwHaHE90R"}},{"cell_type":"markdown","source":["The training script consists of preparing the environment, reading the data, data preparation, model training, evaluating the model and saving/registering the model. This includes specifying the dependencies to import and utilize, setting the seed, defining the input/output arguments of `argparse`, reading the train/test sets, defining the features/target and preprocessing the data by scaling the features with the `MinMaxScaler`. Then the number of samples and features are logged with `MLFlow`. It uses this to then train a `Linear` model using the best parameters from `GridSearchCV` where the `classification_report` and `confusion_matrix` as well as the metrics `accuracy`, `precision`, `recall` and `f1_score` for the train/test sets are logged as `MLFlow` artifacts and metrics. Then the model can be saved and registered.\n"],"metadata":{"id":"BRwPTRIjr75T"}},{"cell_type":"code","source":["import os\n","import random\n","import numpy as np\n","import warnings\n","import argparse\n","import pandas as pd\n","import mlflow\n","import mlflow.sklearn\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.linear_model import LogisticRegression\n","from joblib import parallel_backend\n","from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","from sklearn.metrics import accuracy_score, precision_score\n","from sklearn.metrics import recall_score, f1_score\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","warnings.filterwarnings('ignore')\n","\n","seed_value = 42\n","os.environ['LoanStatus_Linear'] = str(seed_value)\n","random.seed(seed_value)\n","np.random.seed(seed_value)\n","\n","def main():\n","    \"\"\"Main function of the script.\"\"\"\n","\n","    # Input and output arguments\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument('--train_data', type=str,\n","                        help='path to input train data')\n","    parser.add_argument('--test_data', type=str, help='path to input test data')\n","    parser.add_argument('--penalty', required=False, default='l2', type=str)\n","    parser.add_argument('--solver', required=False, default='lbfgs', type=str)\n","    parser.add_argument('--max_iter', required=False, default=100, type=int)\n","    parser.add_argument('--C', required=False, default=1, type=int)\n","    parser.add_argument('--tol', required=False, default=1e-4, type=float)\n","    parser.add_argument('--n_jobs', required=False, default=1, type=int)\n","    parser.add_argument('--registered_model_name', type=str, help='model name')\n","    args = parser.parse_args()\n","\n","    # Start Logging\n","    mlflow.start_run()\n","\n","    # Enable autologging\n","    mlflow.sklearn.autolog()\n","\n","    ###################\n","    #<prepare the data>\n","    ###################\n","    print(\" \".join(f\"{k}={v}\" for k, v in vars(args).items()))\n","\n","    print('Input Train Data:', args.train_data)\n","    print('Input Test Data:', args.test_data)\n","\n","    trainDF = pd.read_csv(args.train_data, low_memory=False)\n","    testDF = pd.read_csv(args.test_data, low_memory=False)\n","\n","    train_label = trainDF[['loan_status']]\n","    test_label = testDF[['loan_status']]\n","\n","    train_features = trainDF.drop(columns = ['loan_status'])\n","    test_features = testDF.drop(columns = ['loan_status'])\n","\n","    print(f\"Training with data of shape {train_features.shape}\")\n","\n","    scaler = MinMaxScaler()\n","    train_features = scaler.fit_transform(train_features)\n","    test_features = scaler.transform(test_features)\n","\n","    mlflow.log_metric('num_samples', train_features.shape[0])\n","    mlflow.log_metric('num_features', train_features.shape[1])\n","\n","    ####################\n","    #</prepare the data>\n","    ####################\n","\n","    ##################\n","    #<train the model>\n","    ##################\n","    # Define model\n","    model = LogisticRegression(penalty=args.penalty,\n","                               solver=args.solver,\n","                               max_iter=args.max_iter,\n","                               C=args.C,\n","                               tol=args.tol,\n","                               random_state=seed_value)\n","\n","    # Fit model\n","    with parallel_backend('threading', n_jobs=args.n_jobs):\n","        model.fit(train_features, train_label)\n","\n","    ##################\n","    #</train the model>\n","    ##################\n","\n","    #####################\n","    #<evaluate the model>\n","    #####################\n","    # Predict\n","    train_label_pred = model.predict(train_features)\n","    test_label_pred = model.predict(test_features)\n","\n","    clr_train = classification_report(train_label, train_label_pred,\n","                                      output_dict=True)\n","    sns.heatmap(pd.DataFrame(clr_train).iloc[:-1,:].T, annot=True)\n","    plt.savefig('clr_train.png')\n","    mlflow.log_artifact('clr_train.png')\n","    plt.close()\n","\n","    clr_test = classification_report(test_label, test_label_pred,\n","                                     output_dict=True)\n","    sns.heatmap(pd.DataFrame(clr_test).iloc[:-1,:].T, annot=True)\n","    plt.savefig('clr_test.png')\n","    mlflow.log_artifact('clr_test.png')\n","    plt.close()\n","\n","    cm_train = confusion_matrix(train_label, train_label_pred)\n","    cm_train = ConfusionMatrixDisplay(confusion_matrix=cm_train)\n","    cm_train.plot()\n","    plt.savefig('cm_train.png')\n","    mlflow.log_artifact('cm_train.png')\n","    plt.close()\n","\n","    cm_test = confusion_matrix(test_label, test_label_pred)\n","    cm_test = ConfusionMatrixDisplay(confusion_matrix=cm_test)\n","    cm_test.plot()\n","    plt.savefig('cm_test.png')\n","    mlflow.log_artifact('cm_test.png')\n","    plt.close()\n","\n","    train_accuracy = accuracy_score(train_label, train_label_pred)\n","    train_precision = precision_score(train_label, train_label_pred)\n","    train_recall = recall_score(train_label, train_label_pred)\n","    train_f1 = f1_score(train_label, train_label_pred)\n","\n","    test_accuracy = accuracy_score(test_label, test_label_pred)\n","    test_precision = precision_score(test_label, test_label_pred)\n","    test_recall = recall_score(test_label, test_label_pred)\n","    test_f1 = f1_score(test_label, test_label_pred)\n","\n","    mlflow.log_metric('train_accuracy', train_accuracy)\n","    mlflow.log_metric('train_precision', train_precision)\n","    mlflow.log_metric('train_recall', train_recall)\n","    mlflow.log_metric('train_f1', train_f1)\n","    mlflow.log_metric('test_accuracy', test_accuracy)\n","    mlflow.log_metric('test_precision', test_precision)\n","    mlflow.log_metric('test_recall', test_recall)\n","    mlflow.log_metric('test_f1', test_f1)\n","\n","    #####################\n","    #</evaluate the model>\n","    #####################\n","\n","    ##########################\n","    #<save and register model>\n","    ##########################\n","    # Registering the model to the workspace\n","    print('Registering the model via MLFlow')\n","    mlflow.sklearn.log_model(\n","        sk_model=model,\n","        registered_model_name=args.registered_model_name,\n","        artifact_path=args.registered_model_name,\n","    )\n","\n","    # Saving the model to a file\n","    mlflow.sklearn.save_model(\n","        sk_model=model,\n","        path=os.path.join(args.registered_model_name, 'trained_model'),\n","    )\n","\n","    ###########################\n","    #</save and register model>\n","    ###########################\n","\n","    # Stop Logging\n","    mlflow.end_run()\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wUq6oxPRI3Nv","executionInfo":{"status":"ok","timestamp":1694048160487,"user_tz":240,"elapsed":194,"user":{"displayName":"Andrew Schultz","userId":"07163353164150645905"}},"outputId":"0bbac4ac-1f20-4843-a7e9-5ee12e809119"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing ./src/main.py\n"]}]},{"cell_type":"markdown","source":[" ## Train the model with specified components\n","To train the model, a `command job` configured with the input specifying the  input data and the hyperparameter conditions, which then runs the `training script` using the specified compute resource, environment, and the parameters specified to be logged needs to be submitted as a job."],"metadata":{"id":"ZOaZt0agZ27A"}},{"cell_type":"code","source":["from azure.ai.ml import command\n","from azure.ai.ml import Input\n","\n","registered_model_name = 'loanstatus_us_linear_model'\n","\n","job = command(\n","    inputs=dict(\n","        train_data=Input(\n","            type='uri_file',\n","            path='azureml://datastores/loanstatus_datastore/paths/trainDF_US.csv',\n","        ),\n","        test_data=Input(\n","            type='uri_file',\n","            path = 'azureml://datastores/loanstatus_datastore/paths/testDF_US.csv',\n","        ),\n","        penalty='l1',\n","        solver='saga',\n","        max_iter=100000,\n","        C=1,\n","        tol=1e-06,\n","        n_jobs=-1,\n","        registered_model_name=registered_model_name,\n","    ),\n","\n","    code='./src/',\n","    command='python main.py --train_data ${{inputs.train_data}} --test_data ${{inputs.test_data}} --penalty ${{inputs.penalty}} --solver ${{inputs.solver}} --max_iter ${{inputs.max_iter}} --n_jobs ${{inputs.n_jobs}} --registered_model_name ${{inputs.registered_model_name}}',\n","    environment='aml-loanstatus-cpu@latest',\n","    compute='cpu-cluster-E8s-v3',\n","    display_name='loanstatus_us_linear_best_prediction',\n",")"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1691363312031},"id":"o7i9SuqRE90V"}},{"cell_type":"markdown","source":["## Submit the job\n","Then this job can be submitted to run in `Azure Machine Learning Studio` using the `create_or_update` command with `ml_client`."],"metadata":{"id":"sqjXP3ICZ27B"}},{"cell_type":"code","source":["ml_client.create_or_update(job)"],"outputs":[{"output_type":"stream","name":"stderr","text":"\r\u001b[32mUploading src (0.01 MBs):   0%|          | 0/6105 [00:00<?, ?it/s]\r\u001b[32mUploading src (0.01 MBs): 100%|██████████| 6105/6105 [00:00<00:00, 395731.86it/s]\n\u001b[39m\n\n"},{"output_type":"execute_result","execution_count":38,"data":{"text/plain":"Command({'parameters': {}, 'init': False, 'name': 'placid_calypso_gckg34lwnd', 'type': 'command', 'status': 'Starting', 'log_files': None, 'description': None, 'tags': {}, 'properties': {'_azureml.ComputeTargetType': 'amlctrain', 'ContentSnapshotId': '0cf215d9-e024-47f4-815b-f9db908877be'}, 'print_as_yaml': True, 'id': '/subscriptions/a134465f-eb15-4297-b902-3c97d4c81838/resourceGroups/aschultzdata/providers/Microsoft.MachineLearningServices/workspaces/ds-ml-env/jobs/placid_calypso_gckg34lwnd', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/cpu-standardds12v2/code/Users/aschultz.data/loanStatus/Models/ML/Linear', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7fdbb0e907f0>, 'serialize': <msrest.serialization.Serializer object at 0x7fdbb0281100>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': 'loanstatus_us_linear_best_prediction', 'experiment_name': 'Linear', 'compute': 'cpu-cluster-E8s-v3', 'services': {'Tracking': {'endpoint': 'azureml://eastus.api.azureml.ms/mlflow/v1.0/subscriptions/a134465f-eb15-4297-b902-3c97d4c81838/resourceGroups/aschultzdata/providers/Microsoft.MachineLearningServices/workspaces/ds-ml-env?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/placid_calypso_gckg34lwnd?wsid=/subscriptions/a134465f-eb15-4297-b902-3c97d4c81838/resourcegroups/aschultzdata/workspaces/ds-ml-env&tid=82f58b44-0a84-4add-9752-ad76c1fdebb1', 'type': 'Studio'}}, 'comment': None, 'job_inputs': {'train_data': {'type': 'uri_file', 'path': 'azureml://datastores/loanstatus_datastore/paths/trainDF_US.csv', 'mode': 'ro_mount'}, 'test_data': {'type': 'uri_file', 'path': 'azureml://datastores/loanstatus_datastore/paths/testDF_US.csv', 'mode': 'ro_mount'}, 'penalty': 'l1', 'solver': 'saga', 'max_iter': '100000', 'C': '1', 'tol': '1e-06', 'n_jobs': '-1', 'registered_model_name': 'loanstatus_us_linear_model'}, 'job_outputs': {'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.placid_calypso_gckg34lwnd', 'mode': 'rw_mount'}}, 'inputs': {'train_data': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7fdbb0281ee0>, 'test_data': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7fdbb0281250>, 'penalty': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7fdbb0281a60>, 'solver': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7fdbb0281eb0>, 'max_iter': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7fdbb02813d0>, 'C': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7fdbb0281790>, 'tol': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7fdbb0435a30>, 'n_jobs': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7fdbb0435550>, 'registered_model_name': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7fdbb0435370>}, 'outputs': {'default': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7fdbb0435d00>}, 'component': CommandComponent({'intellectual_property': None, 'auto_increment_version': True, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': False, 'auto_delete_setting': None, 'name': 'placid_calypso_gckg34lwnd', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/cpu-standardds12v2/code/Users/aschultz.data/loanStatus/Models/ML/Linear', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7fdbb0e907f0>, 'serialize': <msrest.serialization.Serializer object at 0x7fdbb0281730>, 'command': 'python main.py --train_data ${{inputs.train_data}} --test_data ${{inputs.test_data}} --penalty ${{inputs.penalty}} --solver ${{inputs.solver}} --max_iter ${{inputs.max_iter}} --n_jobs ${{inputs.n_jobs}} --registered_model_name ${{inputs.registered_model_name}}', 'code': '/subscriptions/a134465f-eb15-4297-b902-3c97d4c81838/resourceGroups/aschultzdata/providers/Microsoft.MachineLearningServices/workspaces/ds-ml-env/codes/4b2be6c5-8eb0-43d8-a07a-c446dc54ee7d/versions/1', 'environment_variables': {}, 'environment': '/subscriptions/a134465f-eb15-4297-b902-3c97d4c81838/resourceGroups/aschultzdata/providers/Microsoft.MachineLearningServices/workspaces/ds-ml-env/environments/aml-loanstatus-cpu/versions/2', 'distribution': None, 'resources': None, 'queue_settings': None, 'version': None, 'latest_version': None, 'schema': None, 'type': 'command', 'display_name': 'loanstatus_us_linear_best_prediction', 'is_deterministic': True, 'inputs': {'train_data': {'type': 'uri_file', 'path': 'azureml://datastores/loanstatus_datastore/paths/trainDF_US.csv', 'mode': 'ro_mount'}, 'test_data': {'type': 'uri_file', 'path': 'azureml://datastores/loanstatus_datastore/paths/testDF_US.csv', 'mode': 'ro_mount'}, 'penalty': {'type': 'string', 'default': 'l1'}, 'solver': {'type': 'string', 'default': 'saga'}, 'max_iter': {'type': 'string', 'default': '100000'}, 'C': {'type': 'string', 'default': '1'}, 'tol': {'type': 'string', 'default': '1e-06'}, 'n_jobs': {'type': 'string', 'default': '-1'}, 'registered_model_name': {'type': 'string', 'default': 'loanstatus_us_linear_model'}}, 'outputs': {'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.placid_calypso_gckg34lwnd', 'mode': 'rw_mount'}}, 'yaml_str': None, 'other_parameter': {'status': 'Starting', 'parameters': {}}, 'additional_includes': []}), 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': {'Tracking': {'endpoint': 'azureml://eastus.api.azureml.ms/mlflow/v1.0/subscriptions/a134465f-eb15-4297-b902-3c97d4c81838/resourceGroups/aschultzdata/providers/Microsoft.MachineLearningServices/workspaces/ds-ml-env?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/placid_calypso_gckg34lwnd?wsid=/subscriptions/a134465f-eb15-4297-b902-3c97d4c81838/resourcegroups/aschultzdata/workspaces/ds-ml-env&tid=82f58b44-0a84-4add-9752-ad76c1fdebb1', 'type': 'Studio'}}, 'status': 'Starting', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7fdbb0e907f0>}, 'instance_id': '04608a10-d1cb-42bc-86a3-08f9e6fa3263', 'source': 'BUILDER', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': None, 'environment_variables': {}, 'environment': 'aml-loanstatus-cpu:2', 'resources': {'instance_count': 1, 'shm_size': '2g'}, 'queue_settings': None, 'swept': False})","text/html":"<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>Linear</td><td>placid_calypso_gckg34lwnd</td><td>command</td><td>Starting</td><td><a href=\"https://ml.azure.com/runs/placid_calypso_gckg34lwnd?wsid=/subscriptions/a134465f-eb15-4297-b902-3c97d4c81838/resourcegroups/aschultzdata/workspaces/ds-ml-env&amp;tid=82f58b44-0a84-4add-9752-ad76c1fdebb1\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"},"metadata":{}}],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1691363317641},"id":"KKk8TvEHE90W","outputId":"c42ce701-38f4-464f-e92c-63ed76debf1b"}}],"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","language":"python","display_name":"Python 3 (ipykernel)"},"language_info":{"name":"python","version":"3.8.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"microsoft":{"ms_spell_check":{"ms_spell_check_language":"en"}},"kernel_info":{"name":"python3"},"nteract":{"version":"nteract-front-end@1.0.0"}},"nbformat":4,"nbformat_minor":0}
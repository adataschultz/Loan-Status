{
	"name": "Apache Spark GPU-accelerated pools in Azure Synapse Analytics",
	"properties": {
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "gpuPoolLarge",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "30g",
			"driverCores": 4,
			"executorMemory": "60g",
			"executorCores": 12,
			"numExecutors": 2,
			"runAsWorkspaceSystemIdentity": false,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "587256c0-8c32-4599-a3cd-7e862096842d"
			}
		},
		"metadata": {
			"saveOutput": true,
			"synapse_widget": {
				"version": "0.1"
			},
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/a134465f-eb15-4297-b902-3c97d4c81838/resourceGroups/aschultzdata/providers/Microsoft.Synapse/workspaces/spark-loanstatus-trade-east/bigDataPools/gpuPoolLarge",
				"name": "gpuPoolLarge",
				"type": "Spark",
				"endpoint": "https://spark-loanstatus-trade-east.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/gpuPoolLarge",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net",
					"authHeader": null
				},
				"sparkVersion": "3.2",
				"nodeCount": 10,
				"cores": 16,
				"memory": 110,
				"extraHeader": null
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Apache Spark GPU-accelerated pools in Azure Synapse Analytics\r\n",
					"\r\n",
					"Link: https://github.com/MicrosoftDocs/azure-docs/blob/main/articles/synapse-analytics/spark/apache-spark-rapids-gpu.md\r\n",
					"\r\n",
					"Link: https://github.com/MicrosoftDocs/azure-docs/blob/main/articles/synapse-analytics/spark/apache-spark-machine-learning-training.md\r\n",
					"\r\n",
					"Quickstart: Create an Apache Spark GPU-enabled Pool in Azure Synapse Analytics using the Azure portal\r\n",
					"\r\n",
					"Link: https://github.com/MicrosoftDocs/azure-docs/blob/main/articles/synapse-analytics/quickstart-create-apache-gpu-pool-portal.md\r\n",
					"\r\n",
					"GPU-accelerated Apache Spark pools in Azure Synapse Analytics (Preview)\r\n",
					"https://github.com/MicrosoftDocs/azure-docs/blob/main/articles/synapse-analytics/spark/apache-spark-gpu-concept.md\r\n",
					"\r\n",
					"## Train deep learning models\r\n",
					"\r\n",
					"Deep learning models are often data and computation intensive. Because of this, organizations often accelerate their training process with GPU-enabled clusters. In Azure Synapse Analytics, organizations can build models using frameworks like Tensorflow and PyTorch. Then, users can scale up their deep learning models with Horovod and Petastorm.\r\n",
					"\r\n",
					"To learn more about how you can train distributed deep learning models, visit the following guides: \r\n",
					"\r\n",
					"- Tutorial: Distributed training with Horovod and Tensorflow https://github.com/MicrosoftDocs/azure-docs/blob/main/articles/synapse-analytics/machine-learning/tutorial-horovod-tensorflow.md\r\n",
					"\r\n",
					"- Tutorial: Distributed training with Horovod and PyTorch https://github.com/MicrosoftDocs/azure-docs/blob/main/articles/synapse-analytics/machine-learning/tutorial-horovod-pytorch.md\r\n",
					"\r\n",
					"## Improve machine learning scoring workloads\r\n",
					"\r\n",
					"Many organizations rely on large batch scoring jobs to frequently execute during narrow windows of time. To achieve improved batch scoring jobs, you can also use GPU-accelerated Spark pools with Microsoft’s Hummingbird library. With Hummingbird, users can take their traditional, tree-based ML models and compile them into tensor computations. Hummingbird allows users to then seamlessly leverage native hardware acceleration and neural network frameworks to accelerate their ML model scoring without needing to rewrite their models.\r\n",
					"\r\n",
					"Link: https://github.com/Microsoft/hummingbird\r\n",
					"\r\n",
					"## Accelerate ETL workloads\r\n",
					"\r\n",
					"With built-in support for NVIDIA’s RAPIDS Accelerator for Apache Spark, GPU-accelerated Spark pools in Azure Synapse can provide significant performance improvements compared to standard analytical benchmarks without requiring any code changes. Built on top of NVIDIA CUDA and UCX, NVIDIA RAPIDS enables GPU-accelerated SQL, DataFrame operations, and Spark shuffles. Since there are no code changes required to leverage these accelerations, users can also accelerate their data pipelines that rely on Linux Foundation’s Delta Lake or Microsoft’s Hyperspace indexing.\r\n",
					"\r\n",
					"Link: https://nvidia.github.io/spark-rapids/\r\n",
					"\r\n",
					"To learn more about how you can use the NVIDIA RAPIDS Accelerator with your GPU-accelerated pool in Azure Synapse Analytics, visit this guide on how to improve performance with RAPIDS.\r\n",
					"\r\n",
					"Link: https://github.com/MicrosoftDocs/azure-docs/blob/main/articles/synapse-analytics/spark/apache-spark-rapids-gpu.md\r\n",
					""
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Create a GPU-accelerated pool\r\n",
					"\r\n",
					"To simplify the process for creating and managing pools, Azure Synapse takes care of pre-installing low-level libraries and setting up all the complex networking requirements between compute nodes. This integration allows users to get started with GPU- accelerated pools within just a few minutes. To learn more about how to create a GPU-accelerated pool, you can visit the quickstart on [how to create a GPU-accelerated pool](https://github.com/MicrosoftDocs/azure-docs/blob/main/articles/synapse-analytics/quickstart-create-apache-gpu-pool-portal.md).\r\n",
					"\r\n",
					"    [!NOTE]\r\n",
					"\r\n",
					"        GPU-accelerated pools can be created in workspaces located in East US, Australia East, and North Europe.\r\n",
					"        GPU-accelerated pools are only availble with the Apache Spark 3 runtime.\r\n",
					"        You might need to request a limit increase in order to create GPU-enabled clusters.\r\n",
					"\r\n",
					""
				]
			},
			{
				"cell_type": "code",
				"source": [
					"spark.conf.set('spark.rapids.sql.enabled','true')"
				],
				"execution_count": 1
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"!nvidia-smi"
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"RAPIDS Accelerator for Apache Spark\r\n",
					"\r\n",
					"The Spark RAPIDS accelerator is a plugin that works by overriding the physical plan of a Spark job by supported GPU operations, and running those operations on the GPUs, thereby accelerating processing. This library is currently in preview and doesn't support all Spark operations (here is a list of currently supported operators, and more support is being added incrementally through new releases).\r\n",
					"\r\n",
					"Link: https://nvidia.github.io/spark-rapids/docs/supported_ops.html"
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"Cluster configuration options\r\n",
					"\r\n",
					"The RAPIDS Accelerator plugin only supports a one-to-one mapping between GPUs and executors. This means a Spark job would need to request executor and driver resources that can be accommodated by the pool resources (according to the number of available GPU and CPU cores). In order to meet this condition and ensure optimal utilization of all the pool resources, we require the following configuration of drivers and executors for a Spark application running on GPU-enabled pools:\r\n",
					"Pool size \tDriver size options \tDriver cores  \tDriver Memory (GB) \tExecutor cores \tExecutor Memory (GB) \tNumber of Executors\r\n",
					"GPU-Large \tSmall driver \t4 \t30 \t12 \t60 \tNumber of nodes in pool\r\n",
					"GPU-Large \tMedium driver \t7 \t30 \t9 \t60 \tNumber of nodes in pool\r\n",
					"GPU-XLarge \tMedium driver \t8 \t40 \t14 \t80 \t4 * Number of nodes in pool\r\n",
					"GPU-XLarge \tLarge driver \t12 \t40 \t13 \t80 \t4 * Number of nodes in pool\r\n",
					"\r\n",
					"Any workload that does not meet one of the above configurations will not be accepted. This is done to make sure Spark jobs are being run with the most efficient and performant configuration utilizing all available resources on the pool.\r\n",
					"\r\n",
					"The user can set the above configuration through their workload. For notebooks, the user can use the %%configure magic command to set one of the above configurations as shown below. For example, using a large pool with three nodes:"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"%%configure -f\r\n",
					"{\r\n",
					"    \"driverMemory\": \"30g\",\r\n",
					"    \"driverCores\": 4,\r\n",
					"    \"executorMemory\": \"60g\",\r\n",
					"    \"executorCores\": 12,\r\n",
					"    \"numExecutors\": 3\r\n",
					"}"
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"Run a sample Spark job through notebook on an Azure Synapse GPU-accelerated pool\r\n",
					"\r\n",
					"It would be good to be familiar with the basic concepts of how to use a notebook in Azure Synapse Analytics before proceeding with this section. Let's walk through the steps to run a Spark application utilizing GPU acceleration. You can write a Spark application in all the four languages supported inside Synapse, PySpark (Python), Spark (Scala), SparkSQL, and .NET for Spark (C#).\r\n",
					"\r\n",
					"    Create a GPU-enabled pool as described in this quickstart. Link: https://github.com/MicrosoftDocs/azure-docs/blob/main/articles/synapse-analytics/quickstart-create-apache-gpu-pool-portal.md\r\n",
					"\r\n",
					"    Create a notebook and attach it to the GPU-enabled pool you created in the first step.\r\n",
					"\r\n",
					"    Set the configurations as explained in the previous section.\r\n",
					"\r\n",
					"    Create a sample dataframe by copying the below code in the first cell of your notebook:\r\n",
					""
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"emp = [(1, \"Smith\", 10, 100000),\r\n",
					"\t(2, \"Rose\", 20, 97600),\r\n",
					"\t(3, \"Williams\", 20, 110000),\r\n",
					"\t(4, \"Jones\", 10, 80000),\r\n",
					"\t(5, \"Brown\", 40, 60000),\r\n",
					"\t(6, \"Brown\", 30, 78000)]\r\n",
					"\r\n",
					"empColumns = [\"emp_id\", \"name\", \"emp_dept_id\", \"salary\"]\r\n",
					"\r\n",
					"empDF = spark.createDataFrame(data=emp, schema=empColumns)"
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"Now let's do an aggregate by getting the maximum salary per department ID and display the result:"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"resultDF = empDF.groupBy(\"emp_dept_id\").max(\"salary\")\r\n",
					"resultDF.show()"
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"You can see the operations in your query that ran on GPUs by looking into the SQL plan through the Spark History Server: "
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"How to tune your application for GPUs\r\n",
					"\r\n",
					"Most Spark jobs can see improved performance through tuning configuration settings from defaults, and the same holds true for jobs leveraging the RAPIDS accelerator plugin for Apache Spark. This [documentation](https://nvidia.github.io/spark-rapids/docs/tuning-guide.html) provides guidelines on how to tune a Spark job to run on GPUs using the RAPIDS plugin.\r\n",
					"Quotas and resource constraints in Azure Synapse GPU-enabled pools\r\n",
					"Workspace level\r\n",
					"\r\n",
					"Every Azure Synapse workspace comes with a default quota of 50 GPU vCores. In order to increase your quota of GPU cores, please [submit a support request through the Azure portal](https://github.com/MicrosoftDocs/azure-docs/blob/main/articles/synapse-analytics/sql-data-warehouse/sql-data-warehouse-get-started-create-support-ticket.md)."
				]
			}
		]
	}
}